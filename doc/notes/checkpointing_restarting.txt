Using ptatin_driver_basic.app

Section 1: Checkpointing runs
-----------------------------
Determining when to checkpointing can be controlled in several different ways.

1) By enforicing that the code writes a checkpoint file every N steps, but the checkpoint files will will have a common name.
These files are over written each time checkpointing occurs. 
Such functionality useful when you simply need to restart the code on machine which allows a fixed walltime and you want to job chain.
Because the checkpoint files have a common name, job chaining is straight forward as you are may not know the prefix (timestep) of the last step written.
This type of checkpointing is activated via the command line flag
-checkpoint_every N

2) By enforcing that the code writes a checkpoint file every M timesteps. 
These files will have a file name with a unique extension, thus they do not get over-ridden.
This type of checkpointing is activated via the command line flag
-checkpoint_every_nsteps M

3) By enforcing that the code writes a checkpoint file every X cpu minutes. 
This can be useful if you have some time steps which require significantly more time to solve than others.
In this case, simply asking to check point every M timesteps might not be appropriate and you might exceed the walltime before M timesteps are completed.
This type of checkpointing is activated via the command line flag
-checkpoint_every_ncpumins 60.0

All these checkpointing options can be used together to presrve the results obtained from a simulation.
WHen they are used together, I ensure that timestep based checkpoint files are not written twice.
For example, if I asked to checkpoint every 30 mins, and this criterion is activiated at step 10, and the checkpoint_every_nsteps options was used with a value of 10, ptatin will not checkpoint step10 twice.

Section 2: Restarting runs
--------------------------

1) To restart with a specific timestep file, you need to specify the restart prefix via
-restart_prefix step000006 
By default, ptatin will assume that the restart files live in the directory defined by -output_path when you generated the checkpoint file 
Similarily, by default, the restarted job will write output into the same directory specified by the value of -output_path given in the run which generated the checkpoint file.

2) To restart from the last checkpointed file written, you need to specify
-restart

If for some reason you wish to direct the output of you restarted run to a directory different from that set by -output_path in the original job, you are required to specify the following options.
-restart_directory loaction_where_your_checkpoint_files_live
-output_path path_to_new_output_directory


~DAM (Oct 31, 2012)



